{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import hyperiax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "\n",
    "from hyperiax.execution import DependencyTreeExecutor\n",
    "from hyperiax.models import UpLambda\n",
    "from hyperiax.models.functional import pass_up\n",
    "\n",
    "\n",
    "from help_functions.DICAROS import *\n",
    "from help_functions.image_manipulation import *\n",
    "from help_functions.align_shapes import *\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, for into tree, to do reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files\n",
    "corrected_dataset = \"./Papilnodae_dataset/\"\n",
    "\n",
    "\n",
    "#butterfly_tree = read.newick(main_path+\"./paplionade_tree.txt\",format=1)\n",
    "fline=open(corrected_dataset+\"/tree.tree\").readline().rstrip()\n",
    "tree = hyperiax.tree.builders.tree_from_newick(fline)\n",
    "\n",
    "tree.root.data[\"edge_length\"] = 0\n",
    "\n",
    "# variables\n",
    "landmarks = pd.read_csv(corrected_dataset+\"/mean_shapes.csv\",)\n",
    "metadata = pd.read_csv(corrected_dataset+\"/metadata.csv\")\n",
    "\n",
    "\n",
    "\n",
    "landmarks[\"species\"] = landmarks[\"species\"].str.replace(\" \", \"_\")\n",
    "landmarks = landmarks.set_index('species')\n",
    "landmarks = landmarks.drop(columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = jnp.shape(landmarks)\n",
    "d = 2\n",
    "\n",
    "# Rearrange the landmarks to fit the tree\n",
    "node_names = [node.name for node in tree.iter_leaves()]\n",
    "landmarks = landmarks.loc[node_names]\n",
    "\n",
    "\n",
    "d = 2\n",
    "# For each row in landmarks, convert to array \n",
    "gpa_landmarks = [row.reshape(-1,d) for row in landmarks.values]\n",
    "aligned_shapes, final_mean_shape = align_shapes(gpa_landmarks, max_iterations=100)\n",
    "\n",
    "for i, leaf in enumerate(tree.iter_leaves()):\n",
    "    leaf.data[\"value\"] = jnp.array(aligned_shapes[i].flatten())\n",
    "tree.root.data[\"edge_length\"] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare to do reconstrction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu_selector = int(3)\n",
    "\n",
    "available_devices = jax.devices()\n",
    "selected_gpu = available_devices[-1]\n",
    "print(f\"Using device: {selected_gpu}\")\n",
    "\n",
    "# Compile the function for the second GPU\n",
    "fuse_lddmm = jax.jit(fuse_lddmm, device=selected_gpu)\n",
    "\n",
    "\n",
    "up_momentum= pass_up('value','sigma','edge_length')\n",
    "upmodel_momentum = UpLambda(up_momentum, fuse_lddmm)\n",
    "root_exe_momentum = DependencyTreeExecutor(upmodel_momentum, batch_size=5)\n",
    "\n",
    "\n",
    "# Compile the function for the second GPU\n",
    "fuse_edgelength = jax.jit(fuse_edgelength, device=selected_gpu)\n",
    "up_correct_edge= pass_up('edge_length')\n",
    "upmodel_edge = UpLambda(up_correct_edge, fuse_edgelength)\n",
    "root_exe_edgelength = DependencyTreeExecutor(upmodel_edge, batch_size=5)\n",
    "\n",
    "\n",
    "# Correct edge length to adjust for uncertiniaty \n",
    "tree = root_exe_edgelength.up(tree)\n",
    "\n",
    "# Correct sigma\n",
    "sigma = np.mean([find_sigma(node[\"value\"]) for node in tree.iter_leaves()])\n",
    "for leaf in tree.iter_bfs():\n",
    "    leaf['sigma']=jnp.array([sigma]*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do reconstruction \n",
    "tree = root_exe_momentum.up(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for reconstruction on the images \n",
    "\n",
    "Here we lift the image along the branches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First prepare the data \n",
    "\n",
    "- First find the image\n",
    "- match the image, to the shape data (for the speciment)\n",
    "- replace the mean shape in the tip, with the speciment data \n",
    "- repeat reconstruction and apply the diffemorphic transformation to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.mime import image\n",
    "\n",
    "\n",
    "image_path = \"./Papilnodae_dataset/example_images\"\n",
    "\n",
    "individual_landmarks = pd.read_csv(corrected_dataset+\"/speciment_shapes.csv\")\n",
    "\n",
    "n_steps = 100\n",
    "sigma_factor = 1\n",
    "depth = 0\n",
    "n_images = 50 \n",
    "\n",
    "\n",
    "image_idx_list = [46,90,61,16,31,65,13,89] # Images used for the paper\n",
    "# list full path of images\n",
    "image = os.listdir(image_path)[image_idx_list[3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found node for species Euryades_corethrus: Euryades_corethrus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract gbifID and get landmarks\n",
    "local_gbifid_int = int(image.split(\"_\", 6)[5])\n",
    "leaf_landmarks = individual_landmarks[individual_landmarks[\"gbifID\"] == local_gbifid_int]\n",
    "\n",
    "    \n",
    "# Get species name\n",
    "leaf_species = leaf_landmarks.iloc[0][\"species\"]\n",
    "leaf_species = leaf_species.replace(\" \", \"_\") if leaf_species else None\n",
    "\n",
    "# Get landmark coordinates and remove specific points\n",
    "leaf_landmarks = leaf_landmarks.iloc[0, 3:].values[:]\n",
    "leaf_landmarks = np.delete(leaf_landmarks, [181,180,59,58])\n",
    "\n",
    "# Find matching species in tree\n",
    "leaf_node = None\n",
    "for leaf in tree.iter_leaves():\n",
    "    if leaf.name == leaf_species:\n",
    "        leaf_node = leaf\n",
    "        break\n",
    "        \n",
    "if leaf_node is None:\n",
    "    print(f\"No node found for species {leaf_species}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Found node for species {leaf_species}: {leaf_node.name}\")\n",
    "\n",
    "image_path = os.path.join(image_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputdir_gen_butterfly = f\"Output_folder/manipulated_images_butterfly/\"\n",
    "os.makedirs(outputdir_gen_butterfly, exist_ok=True)\n",
    "\n",
    "outputdir_butterfly = outputdir_gen_butterfly+leaf_species\n",
    "os.makedirs(outputdir_butterfly, exist_ok=True)\n",
    "\n",
    "outputdir_gen_tree = f\"Output_folder/manipulated_images_tree/\"\n",
    "os.makedirs(outputdir_gen_tree, exist_ok=True)\n",
    "\n",
    "outputdir_tree = outputdir_gen_tree+leaf_species\n",
    "os.makedirs(outputdir_tree, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we plot the  tree\n",
    "\n",
    "We first plot the point in the tree, because we need the length of each branch, before they are adjusted from the independent contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "fline=open(corrected_dataset+\"./tree.tree\").readline().rstrip()\n",
    "tree_plot = hyperiax.tree.builders.tree_from_newick(fline)\n",
    "tree_plot.root.data[\"edge_length\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "# The tip, which we wanna trail from - the name has to match with the tip name \n",
    "add_trail = leaf_species.replace(\"_\", \" \")\n",
    "add_trail\n",
    "\n",
    "# Adjusting name for plotting pourposes\n",
    "for leaf_plot in tree_plot.iter_bfs():\n",
    "    if len(leaf_plot.children) !=0:\n",
    "        leaf_plot.name = \"\"\n",
    "    else: \n",
    "        leaf_plot.name = leaf_plot.name+\"  \"\n",
    "        leaf_plot.name = leaf_plot.name.replace('_', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find leaf for: Euryades corethrus\n",
      "Papilio phestus  \n",
      "Papilio ambrax  \n",
      "Papilio polytes  \n",
      "Papilio protenor  \n",
      "Papilio memnon  \n",
      "Papilio deiphobus  \n",
      "Papilio antimachus  \n",
      "Papilio gigon  \n",
      "Papilio polyxenes  \n",
      "Papilio zelicaon  \n",
      "Papilio xuthus  \n",
      "Papilio glaucus  \n",
      "Papilio troilus  \n",
      "Papilio slateri  \n",
      "Papilio thoas  \n",
      "Papilio cresphontes  \n",
      "Papilio aristodemus  \n",
      "Parides photinus  \n",
      "Parides eurimedes  \n",
      "Parides agavus  \n",
      "Euryades corethrus  \n",
      "Match found\n"
     ]
    }
   ],
   "source": [
    "# Find the correct leaf and start there\n",
    "print(f\"Find leaf for: {add_trail}\")\n",
    "flag = False\n",
    "for leaf_plot in tree_plot.iter_leaves_dfs():    \n",
    "    print(leaf_plot.name)\n",
    "    if leaf_plot.name[:-2] == add_trail:\n",
    "        flag = True\n",
    "        print(\"Match found\")\n",
    "        break\n",
    "if not flag:\n",
    "    print(\"No trail found\")\n",
    "    sys.exit()\n",
    "\n",
    "figure_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hyperiax.tree.plot_utils import *\n",
    "fig, axs = plt.subplots(figsize=(8, 6))\n",
    "depth_counter = 0\n",
    "time_points_saved =[]\n",
    "\n",
    "plot_tree_(tree_plot, ax=axs, inc_names=True)\n",
    "axs.axis('off')\n",
    "axs.plot(leaf_plot[\"x_temp\"], leaf_plot[\"y_temp\"], 'ro', markersize=10)\n",
    "plt.savefig(f'{outputdir_tree}/img_{depth_counter}_{0}.png', bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "\n",
    "total_distance = 0\n",
    "current_leaf = leaf_plot\n",
    "while current_leaf.parent is not None:\n",
    "    total_distance += current_leaf[\"edge_length\"]\n",
    "    current_leaf = current_leaf.parent\n",
    "\n",
    "\n",
    "# Do the lift \n",
    "while leaf_plot.parent is not None:\n",
    "\n",
    "    \n",
    "    branch_distance = leaf_plot[\"edge_length\"]\n",
    "    branch_plots = int((branch_distance / total_distance) * n_images)\n",
    "    if branch_plots <1: # if the branch is too short, we artifical add one image \n",
    "        branch_plots = 1\n",
    "    time_points = np.floor(np.linspace(0,99,branch_plots+1)).astype(int)\n",
    "    time_points_saved.append(time_points[:-1]) # save for the other tree \n",
    "    \n",
    "    # Convert these to timepoints, in our scale 0 to 99, make integer\n",
    "    y_positions = np.linspace(leaf_plot.data[\"y_temp\"], leaf_plot.parent.data[\"y_temp\"], 100)[time_points[:-1]]\n",
    "    x_positions = np.linspace(leaf_plot.data[\"x_temp\"], leaf_plot.data[\"x_temp\"], 100)[time_points[:-1]]  \n",
    "\n",
    "    for x_temp, y_temp,time_p in zip(x_positions, y_positions,time_points):\n",
    "        fig, axs = plt.subplots(figsize=(8, 6))\n",
    "        plot_tree_(tree_plot, ax=axs, inc_names=True)\n",
    "        axs.axis('off')\n",
    "\n",
    "        axs.plot(x_temp, y_temp, 'ro', markersize=10)\n",
    "        plt.savefig(f'{outputdir_tree}/img_{depth_counter}_{time_p}.png', bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    leaf_plot = leaf_plot.parent\n",
    "    depth_counter += 1\n",
    "\n",
    "\n",
    "# Make the root dot \n",
    "fig, axs = plt.subplots(figsize=(8, 6))\n",
    "plot_tree_(tree_plot, ax=axs, inc_names=True)\n",
    "axs.plot(leaf_plot.data[\"x_temp\"], 0, 'ro', markersize=10)\n",
    "\n",
    "axs.axis('off')\n",
    "plt.savefig(f'{outputdir_tree}/img_{depth_counter}_{0}.png', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to generate the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chunker(seq, size):\n",
    "# Yield successive chunks of size `size` from `seq`.\n",
    "    for pos in range(0, len(seq)//2, size):  # Divide length by 2 since points are pairs\n",
    "        yield seq[2*pos:2*(pos + size)]  # Scale indices by 2 to get correct point pairs\n",
    "\n",
    "# Select leaf node using provided \n",
    "# flow arbitrary points of N\n",
    "def ode_Hamiltonian_advect(c,y):\n",
    "    t,x,chart = c\n",
    "    qp, = y\n",
    "    q = qp[0]\n",
    "    p = qp[1]\n",
    "\n",
    "    dxt = jnp.tensordot(M.K(x,q),p,(1,0)).reshape((-1,M.m))\n",
    "    return dxt\n",
    "\n",
    "# flow arbitrary points of backwards\n",
    "def ode_Hamiltonian_advect_rev(c,y):\n",
    "    t,x,chart = c\n",
    "    qp, = y\n",
    "    q = qp[0]\n",
    "    p = qp[1]\n",
    "\n",
    "    dxt = -jnp.tensordot(M.K(x,q),p,(1,0)).reshape((-1,M.m))\n",
    "    return dxt\n",
    "\n",
    "\n",
    "from jaxgeometry.manifolds.landmarks import landmarks   \n",
    "from jaxgeometry.Riemannian import metric\n",
    "from jaxgeometry.dynamics import Hamiltonian\n",
    "from jaxgeometry.stochastics import Brownian_coords\n",
    "from jaxgeometry.Riemannian import Log\n",
    "from jaxgeometry.dynamics import flow_differential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the correct leaf for the reconstructed tree\n",
    "for leaf in tree.iter_leaves():\n",
    "    if leaf.name == leaf_species:\n",
    "        leaf_node = leaf\n",
    "        break\n",
    "\n",
    "n_images=50\n",
    "\n",
    "padding=125\n",
    "n_steps = 100\n",
    "sigma_factor = 1\n",
    "depth = 0\n",
    "\n",
    "# Add padding and center the image\n",
    "new_image, offset = add_padding_and_center(image_path, padding)\n",
    "\n",
    "# Convert landmarks to JAX array and adjust for padding offset\n",
    "iterative_start_points = jnp.array(leaf_landmarks, dtype=jnp.float32) # type: ignore\n",
    "iterative_start_points = iterative_start_points.at[0::2].set(iterative_start_points[::2] + offset[0])\n",
    "iterative_start_points = iterative_start_points.at[1::2].set(iterative_start_points[1::2] + offset[1])\n",
    "\n",
    "# Store original landmarks\n",
    "image_landmarks = iterative_start_points.copy()\n",
    "# Get dimensions of padded image\n",
    "height, width = new_image.shape[:2]\n",
    "\n",
    "# Create grid of points covering the image\n",
    "x, y = np.meshgrid(np.linspace(0, width-1, width), np.linspace(0, height-1, height))\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "org_img_coords = np.vstack((x, y)).T.flatten()\n",
    "\n",
    "# Set processing parameters\n",
    "chunk_size = 1000 * 1000\n",
    "total_points = len(org_img_coords) // 2\n",
    "\n",
    "# Set time steps for evolution\n",
    "_dts = dts(n_steps=n_steps)\n",
    "\n",
    "\n",
    "n_landmarks = int(len(image_landmarks)/d)\n",
    "iter_image = new_image.copy()\n",
    "\n",
    "\n",
    "depth = 0 \n",
    "while leaf and leaf.parent:\n",
    "    # Estiamte contrast \n",
    "    sigma_k = leaf['sigma']*sigma_factor\n",
    "    M = landmarks(n_landmarks,k_sigma=sigma_k*jnp.eye(2))\n",
    "    metric.initialize(M)\n",
    "    Brownian_coords.initialize(M)\n",
    "    Hamiltonian.initialize(M)\n",
    "    Log.initialize(M,f=M.Exp_Hamiltonian)\n",
    "    Hamiltonian.initialize(M)\n",
    "    M.Hamiltonian_advect_rev = lambda xs,qps,dts: integrate(ode_Hamiltonian_advect_rev,None,\n",
    "                                                        xs[0].reshape((-1,M.m)),xs[1],dts,qps[::-1])\n",
    "    \n",
    "    parent_landmarks = leaf.parent.data[\"value\"]\n",
    "        \n",
    "    child_landmarks,grid_points_moved,_,_,transform_params= align_A_to_B(image_landmarks,parent_landmarks, org_img_coords)\n",
    "\n",
    "\n",
    "    q = M.coords(child_landmarks)\n",
    "    v = (parent_landmarks, [0])\n",
    "    p = M.Log(q, v)[0]\n",
    "        \n",
    "    (_, qps, _) = M.Hamiltonian_dynamics(q, p, _dts)\n",
    "\n",
    "    # Apply on reversred coordinates\n",
    "    results = np.empty((n_steps, total_points, 2))\n",
    "\n",
    "    # Process chunks\n",
    "    for i, chunk in enumerate(chunker(grid_points_moved, chunk_size)):\n",
    "        _, xs_chunk = M.Hamiltonian_advect_rev((chunk, M.chart()), qps, _dts)\n",
    "        # Ensure the slice matches the chunk size \n",
    "        results[:, i * chunk_size:(i + 1) * chunk_size, :] = xs_chunk\n",
    "\n",
    "\n",
    "\n",
    "    # Loop throuh frames \n",
    "    for idx in time_points_saved[depth]:\n",
    "        # Find landmarks now, and where they are in the interpolated image\n",
    "        # hit points \n",
    "        def plot_frame(qps, idx, parent_landmarks, image_landmarks, results, iter_image, output_dir, depth,transform_params):\n",
    "            plt.figure(figsize=(1.9, 1.9))\n",
    "            plt.imshow(interpolate_image(parent_landmarks,image_landmarks, results[idx, :].flatten(),iter_image,grid_points_moved,transform_params))\n",
    "            # Make a scatter, with black color stars\n",
    "            plt.axis('off')\n",
    "            # Save figure\n",
    "            plt.tight_layout(pad=0)\n",
    "            plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "            plt.savefig(f'{output_dir}/img_{depth}_{idx}.png', dpi=660)\n",
    "            plt.close()\n",
    "                       \n",
    "        plot_frame(qps, idx, parent_landmarks, image_landmarks, results, iter_image, outputdir_butterfly, depth,transform_params)\n",
    "            \n",
    "    # Update the iterative image, to next level, along with landmarks \n",
    "    iter_image = interpolate_image(parent_landmarks,image_landmarks, results[n_steps-1, :].flatten(),iter_image,grid_points_moved,transform_params)\n",
    "    _,_,_,image_landmarks,_ = align_A_to_B(image_landmarks,parent_landmarks, qps[n_steps-1][0],transform_params)\n",
    "    child_landmarks = qps[n_steps-1][0]\n",
    "\n",
    "    # Next\n",
    "    leaf = leaf.parent\n",
    "    depth += 1 \n",
    "\n",
    "    # When we end at the root, make sure to plot it\n",
    "    if leaf.parent is None: \n",
    "        plt.figure(figsize=(1.9, 1.9))\n",
    "        plt.imshow(iter_image)\n",
    "        # Make a scatter, with black color stars\n",
    "        plt.axis('off')\n",
    "        # Save figure\n",
    "        plt.tight_layout(pad=0)\n",
    "        plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "        plt.savefig(f'{outputdir_butterfly}/img_{depth}_{0}.png', dpi=660)\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the final gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#from PIL import Image\n",
    "import re\n",
    "\n",
    "def sort_png_files(png_files):\n",
    "    def extract_numbers(filename):\n",
    "        #Match any string, and then the numbers\n",
    "        match = re.match(r'img_(\\d+)_(\\d+)\\.png', filename)\n",
    "        if match:\n",
    "            return int(match.group(1)), int(match.group(2))\n",
    "        return 0, 0\n",
    "\n",
    "    return sorted(png_files, key=extract_numbers)\n",
    "\n",
    "\n",
    "def pngs_to_gif(directory, output_gif,rotation=0):\n",
    "    # List all PNG files in the directory with the pattern figure_X.png\n",
    "    png_files = sorted([f for f in os.listdir(directory) if f.startswith(\"img\") and f.endswith(\".png\")], key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "    png_files = sort_png_files(png_files)\n",
    "\n",
    "    images = []\n",
    "    for png_file in png_files:\n",
    "        png_path = os.path.join(directory, png_file)\n",
    "        img = Image.open(png_path)\n",
    "        # rotate image 90 degrees\n",
    "        img = img.rotate(rotation)\n",
    "        images.append(img)\n",
    "\n",
    "    # Check if images list is not empty\n",
    "    if images:\n",
    "        first_image, *remaining_images = images\n",
    "        first_image.save(output_gif, save_all=True, append_images=remaining_images, duration=100, loop=1)\n",
    "    else:\n",
    "        print(\"No images found in the provided directory.\")\n",
    "\n",
    "# Example usage\n",
    "pngs_to_gif(f'{outputdir_tree}', f'./Output_folder/{leaf_species}_tree.gif',rotation=270)\n",
    "pngs_to_gif(f'{outputdir_butterfly}', f'./Output_folder/{leaf_species}butterfly.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
